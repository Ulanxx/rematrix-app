{
  "pages": [
    {
      "duration": 12.5,
      "keyPoints": [
        "拒绝智能涌现神话",
        "Agent 关进规则之笼",
        "平衡智能与确定性"
      ],
      "narration": "当智能涌现的滤镜被生产环境击碎，Agent 的失控成了研发者的噩梦。今天我们不谈神话，只谈如何把这头名为 LLM 的野兽关进工程规范的笼子里。",
      "pageNumber": 1,
      "visualSuggestions": [
        "深邃背景中剧烈扭动的淡蓝色 Agent 粒子球",
        "大字标题：Agent 生产之殇",
        "副标题：如何将 LLM 的不确定性关进工程沙盒"
      ]
    },
    {
      "duration": 10,
      "keyPoints": [
        "工程熵增与概率抽样",
        "齿轮 vs 云团",
        "确定性代码封装黑盒"
      ],
      "narration": "传统系统靠齿轮咬合般确定，但 LLM 本质上是概率抽样机器。作为工程师，你的核心矛盾在于：如何用确定性的代码去封装一个天然不确定的黑盒。",
      "pageNumber": 2,
      "visualSuggestions": [
        "对比图：左侧精密齿轮，右侧变幻云团",
        "动态演示：数据进入云团后产生随机概率方向箭头"
      ]
    },
    {
      "duration": 15,
      "keyPoints": [
        "拒绝 LLM 函数化思维",
        "输出分布的不稳定性",
        "Prompt 微调的连锁反应"
      ],
      "narration": "千万别把 LLM 当成普通函数。标准函数是单向且稳健的，而 LLM 的输出分布决定了它的决策具有概率性波动。一次 Prompt 的微调，就可能导致整个业务逻辑链条的全盘崩溃。",
      "pageNumber": 3,
      "visualSuggestions": [
        "函数列表对比：f(x)=y 的唯一连线 vs 多重阴影输出",
        "警告图标：闪烁的 Prompt 提示词像易碎纸张"
      ]
    },
    {
      "duration": 12,
      "keyPoints": [
        "警惕实验室幻觉",
        "长 Context 稀释注意力",
        "指令遗忘与自由发挥"
      ],
      "narration": "警惕实验室幻觉。在短上下文的 Demo 里，它们看起来无所不能。但在真实的生产环境，长 Context 会稀释模型的注意力，让它遗忘原始指令，开始毫无逻辑的自由发挥。",
      "pageNumber": 4,
      "visualSuggestions": [
        "对比：左侧干净实验室短文本精准反应，右侧生产环境长上下文下眼神涣散的 Agent"
      ]
    },
    {
      "duration": 14.5,
      "keyPoints": [
        "多 Agent 是错误放大器",
        "偏差级数级放大",
        "自信的错误闭环"
      ],
      "narration": "多 Agent 协作往往是错误放大器。分工不一定意味着变聪明。微小的偏差会在环节间传递并被后续环节视作‘事实’去合理化，最终形成一个逻辑自洽却错得离谱的行为闭环。",
      "pageNumber": 5,
      "visualSuggestions": [
        "三个 Agent 线性排布，偏差几何级放大",
        "产出球体变形，标注：自信的错误"
      ]
    },
    {
      "duration": 13,
      "keyPoints": [
        "控制流的致命直接连接",
        "LLM 三无特征：无幂等、无边界、无 Trace",
        "不可逆操作灾难"
      ],
      "narration": "最危险的操作是将 LLM 直接连上核心控制流。它没有类型边界，不保障幂等性。在不可逆的数据操作中引入这种不确定性，是由于无法重试和回滚带来的真正灾难。",
      "pageNumber": 6,
      "visualSuggestions": [
        "流程图：LLM 直接修改数据库（红叉）",
        "标注：禁止直接驱动敏感业务流"
      ]
    },
    {
      "duration": 12,
      "keyPoints": [
        "收回决策终审权",
        "角色降级：建议者而非决策官",
        "逻辑硬编码固化"
      ],
      "narration": "法则一：收回决策终审权。Agent 应被降级为‘执行建议者’而非‘决策官’。敏感逻辑必须固化在硬编码中，让 LLM 只处理非结构化信息，严禁其驱动敏感流。",
      "pageNumber": 7,
      "visualSuggestions": [
        "法官席上的硬编码模块，LLM 作为证人递交建议",
        "关键逻辑锁进密码保险箱"
      ]
    },
    {
      "duration": 11.5,
      "keyPoints": [
        "构建外部状态机",
        "Context Window 不可靠性",
        "强制状态共识"
      ],
      "narration": "法则二：构建外部状态机。Context Window 极其不可靠，随时会丢失记忆。不要让模型猜用户聊到了哪一步，而要从外部系统通过结构化存储给它注入强制的状态共识。",
      "pageNumber": 8,
      "visualSuggestions": [
        "外部数据库图标连接 Agent 标注为‘状态机’",
        "模型查看系统快照而非聊天记录"
      ]
    },
    {
      "duration": 11,
      "keyPoints": [
        "设计熔断与降级",
        "构建三道防线护栏",
        "防止幻觉级联爆炸"
      ],
      "narration": "法则三：设计熔断与降级。当模型输出不合法时，系统必须有保底逻辑。通过输出干预和工具拦截构建护栏，在幻觉引发级联爆炸前，强制切断连接。",
      "pageNumber": 9,
      "visualSuggestions": [
        "输出端口的过滤网（Guardrails）",
        "展示：校验 -> 拦截 -> 确认防线"
      ]
    },
    {
      "duration": 10.5,
      "keyPoints": [
        "工程规范压缩不确定性",
        "确定性 > 聪明度",
        "最好的 Agent 是守规矩的"
      ],
      "narration": "成熟的 AI 系统，是通过高强度的工程规范去压缩智能的不确定性空间。因为在生产环境中，一个守规矩的 Agent，永远比一个不可控的聪明天才要有价值得多。",
      "pageNumber": 10,
      "visualSuggestions": [
        "钢结构工程框架包裹发光智能核心",
        "金句：确定性 > 聪明度"
      ]
    }
  ],
  "metadata": {
    "tone": "严肃、警示、架构师视野",
    "style": "科技硬核/工程实战",
    "totalDuration": 122
  },
  "fullScript": "当智能涌现的滤镜被生产环境击碎，Agent 的失控成了研发者的噩梦。今天我们不谈神话，只谈如何把这头名为 LLM 的野兽关进工程规范的笼子里。传统系统靠齿轮咬合般确定，但 LLM 本质上是概率抽样机器。作为工程师，你的核心矛盾在于：如何用确定性的代码去封装一个天然不确定的黑盒。千万别把 LLM 当成普通函数。标准函数是单向且稳健的，而 LLM 的输出分布决定了它的决策具有概率性波动。一次 Prompt 的微调，就可能导致整个业务逻辑链条的全盘崩溃。警惕实验室幻觉。在短上下文的 Demo 里，它们看起来无所不能。但在真实的生产环境，长 Context 会稀释模型的注意力，让它遗忘原始指令，开始毫无逻辑的自由发挥。多 Agent 协作往往是错误放大器。分工不一定意味着变聪明。微小的偏差会在环节间传递并被后续环节视作‘事实’去合理化，最终形成一个逻辑自洽却错得离谱的行为闭环。最危险的操作是将 LLM 直接连上核心控制流。它没有类型边界，不保障幂等性。在不可逆的数据操作中引入这种不确定性，是由于无法重试和回滚带来的真正灾难。法则一：收回决策终审权。Agent 应被降级为‘执行建议者’而非‘决策官’。敏感逻辑必须固化在硬编码中，让 LLM 只处理非结构化信息，严禁其驱动敏感流。法则二：构建外部状态机。Context Window 极其不可靠，随时会丢失记忆。不要让模型猜用户聊到了哪一步，而要从外部系统通过结构化存储给它注入强制的状态共识。法则三：设计熔断与降级。当模型输出不合法时，系统必须有保底逻辑。通过输出干预和工具拦截构建护栏，在幻觉引发级联爆炸前，强制切断连接。成熟的 AI 系统，是通过高强度的工程规范去压缩智能的不确定性空间。因为在生产环境中，一个守规矩的 Agent，永远比一个不可控的聪明天才要有价值得多。"
}